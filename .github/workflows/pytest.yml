# # This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# # For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

# name: pytest

# on:
#   push:
#     branches: ["master", "release-*"]
#   pull_request:
#     branches: ["master", "release-*"]

# # we want an ongoing run of this workflow to be canceled by a later commit
# # so that there is only one concurrent run of this workflow for each branch
# concurrency:
#   group: pytest-${{ github.head_ref || github.sha }}
#   cancel-in-progress: true

# jobs:
#   pytest:
#     runs-on: ${{ matrix.os }}
#     strategy:
#       fail-fast: false
#       matrix:
#         os: [ubuntu-latest]
#         python-version: ["3.8", "3.9", "3.10"]
#         test-markers: ["not distributed", "distributed"]
#         include:
#           - python-version: "3.8"
#             pytorch-version: 1.13.0
#             torchscript-version: 1.10.2
#             ray-version: 2.0.0
#           - python-version: "3.9"
#             pytorch-version: 1.13.0
#             torchscript-version: 1.10.2
#             ray-version: 2.2.0
#           - python-version: "3.10"
#             pytorch-version: nightly
#             torchscript-version: 1.10.2
#             ray-version: 2.3.0 # nightly
#     env:
#       PYTORCH: ${{ matrix.pytorch-version }}
#       MARKERS: ${{ matrix.test-markers }}
#       NEUROPOD_BASE_DIR: "/usr/local/lib/neuropod"
#       NEUROPOD_VERISON: "0.3.0-rc6"
#       TORCHSCRIPT_VERISON: ${{ matrix.torchscript-version }}
#       RAY_VERSION: ${{ matrix.ray-version }}
#       AWS_ACCESS_KEY_ID: ${{ secrets.LUDWIG_TESTS_AWS_ACCESS_KEY_ID }}
#       AWS_SECRET_ACCESS_KEY: ${{ secrets.LUDWIG_TESTS_AWS_SECRET_ACCESS_KEY }}
#       KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
#       KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}

#     name: py${{ matrix.python-version  }}, torch-${{ matrix.pytorch-version }}, ${{ matrix.test-markers }}, ${{ matrix.os }}, ray ${{ matrix.ray-version }}
#     services:
#       minio:
#         image: fclairamb/minio-github-actions
#         env:
#           MINIO_ACCESS_KEY: minio
#           MINIO_SECRET_KEY: minio123
#         ports:
#           - 9000:9000

#     timeout-minutes: 90
#     steps:
#       - name: Setup ludwigai/ludwig-ray container for local testing with act.
#         if: ${{ env.ACT }}
#         run: |
#           curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -
#           sudo apt-get install -y nodejs
#           sudo mkdir -p /opt/hostedtoolcache/
#           sudo chmod 777 -R /opt/hostedtoolcache/
#       - uses: actions/checkout@v2
#       - name: Set up Python ${{ matrix.python-version }}
#         uses: actions/setup-python@v2
#         with:
#           python-version: ${{ matrix.python-version }}

#       - name: Setup Linux
#         if: runner.os == 'linux'
#         run: |
#           sudo apt-get install -y cmake libsndfile1

#       - name: Setup macOS
#         if: runner.os == 'macOS'
#         run: |
#           brew install libuv

#       - name: pip cache
#         if: ${{ !env.ACT }}
#         uses: actions/cache@v2
#         with:
#           path: ~/.cache/pip
#           key: ${{ runner.os }}-pip-py${{ matrix.python-version }}-torch${{ matrix.pytorch-version }}-${{ matrix.test-markers }}-${{ hashFiles('requirements*.txt', '.github/workflows/pytest.yml') }}

#       - name: Install dependencies
#         env:
#           HOROVOD_WITH_PYTORCH: 1
#           HOROVOD_WITHOUT_MPI: 1
#           HOROVOD_WITHOUT_TENSORFLOW: 1
#           HOROVOD_WITHOUT_MXNET: 1
#         run: |
#           python --version
#           pip --version
#           python -m pip install -U pip
#           cmake --version

#           if [ "$MARKERS" != "distributed" ]; then
#             # Skip distributed and hyperopt requirements to test optional imports
#             echo > requirements-temp && mv requirements-temp requirements_distributed.txt
#             echo > requirements-temp && mv requirements-temp requirements_hyperopt.txt
#             # Skip distributed tree requirement (lightgbm-ray)
#             cat requirements_tree.txt | sed '/^lightgbm-ray/d' > requirements-temp && mv requirements-temp requirements_tree.txt
#           fi

#           if [ "$PYTORCH" == "nightly" ]; then
#             cat requirements.txt | sed '/^torch[>=<]/d' | sed '/^torchtext[>=<]/d' | sed '/^torchvision[>=<]/d' | sed '/^torchaudio[>=<]/d' > requirements-temp && mv requirements-temp requirements.txt
#             extra_index_url=https://download.pytorch.org/whl/nightly/cpu
#             pip install --pre torch==2.0.0.dev20230213+cpu torchtext torchvision torchaudio --extra-index-url $extra_index_url
#           else
#             extra_index_url=https://download.pytorch.org/whl/cpu
#             pip install torch==$PYTORCH torchtext torchvision torchaudio --extra-index-url $extra_index_url
#           fi
#           pip install protobuf==3.20.1 # https://github.com/databrickslabs/dbx/issues/257

#           if [ "$MARKERS" == "distributed" ]; then
#             if [ "$RAY_VERSION" == "nightly" ]; then
#               # NOTE: hardcoded for python 3.10 on Linux
#               pip install https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-3.0.0.dev0-cp310-cp310-manylinux2014_x86_64.whl
#             else
#               # installing `six` early resolves ModuleNotFound error in ray==2.1.0
#               pip install six
#               pip install ray==$RAY_VERSION
#             fi
#             ray_expected=$(python -c "import ray; print(ray.__version__)")
#           fi

#           torch_expected=$(python -c "import torch; print(torch.__version__)")

#           pip install --no-build-isolation --no-use-pep517 ConfigSpace # temporary fix: https://github.com/automl/ConfigSpace/issues/173
#           pip install '.[test]' --extra-index-url $extra_index_url
#           pip list

#           python -c "import torch; assert torch.__version__ == \"$torch_expected\", f\"torch {torch.__version__} != $torch_expected\""
#           if [ "$MARKERS" == "distributed" ]; then
#             python -c "import ray; assert ray.__version__ == \"$ray_expected\", f\"ray {ray.__version__} != $ray_expected\""
#           else
#             python -c "import importlib.util; assert importlib.util.find_spec('ray') is None, \"found ray but expected it to not be installed\""
#           fi
#         shell: bash

#       - name: Install Neuropod backend
#         run: |
#           sudo mkdir -p "$NEUROPOD_BASE_DIR"
#           curl -L https://github.com/uber/neuropod/releases/download/v${{ env.NEUROPOD_VERISON }}/libneuropod-cpu-linux-v${{ env.NEUROPOD_VERISON }}-torchscript-${{ env.TORCHSCRIPT_VERISON }}-backend.tar.gz | sudo tar -xz -C "$NEUROPOD_BASE_DIR"
#         shell: bash

#       - name: Reinstall Horovod if necessary
#         if: matrix.test-markers == 'distributed'
#         env:
#           HOROVOD_WITH_PYTORCH: 1
#           HOROVOD_WITHOUT_MPI: 1
#           HOROVOD_WITHOUT_TENSORFLOW: 1
#           HOROVOD_WITHOUT_MXNET: 1
#         run: |
#           HOROVOD_BUILT=$(python -c "import horovod.torch; horovod.torch.nccl_built(); print('SUCCESS')" || true)
#           if [[ $HOROVOD_BUILT != "SUCCESS" ]]; then
#             pip uninstall -y horovod
#             pip install --no-cache-dir git+https://github.com/horovod/horovod.git@master
#           fi
#           horovodrun --check-build
#         shell: bash

#       - name: Tests
#         run: |
#           RUN_PRIVATE=1 LUDWIG_TEST_SUITE_TIMEOUT_S=4500 pytest -v --timeout 300 --durations 100 -m "$MARKERS and not slow or benchmark" --junitxml pytest.xml tests

#       - name: Upload Unit Test Results
#         if: ${{ always() && !env.ACT }}
#         uses: actions/upload-artifact@v2
#         with:
#           name: Unit Test Results (Python ${{ matrix.python-version }} ${{ matrix.test-markers }})
#           path: pytest.xml

#   event_file:
#     name: "Event File"
#     runs-on: ubuntu-latest

#     steps:
#       - name: Upload
#         if: ${{ !env.ACT }}
#         uses: actions/upload-artifact@v2
#         with:
#           name: Event File
#           path: ${{ github.event_path }}
